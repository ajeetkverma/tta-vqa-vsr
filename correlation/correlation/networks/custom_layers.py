import torch
import torch.nn as nn
import torch.nn.functional as F

try:
    import correlation_cpp
except ImportError as e:
    print(e, 'Cannot run in CPU mode. See README.md for installing'
        ' correlation cpp library')

try:
    import correlation_cuda
except ImportError as e:
    print(e, 'Cannot run in CUDA mode. See README.md for installing'
        ' correlation cuda library')

class Correlation(nn.Module):
    def __init__(self, pad_size=20, kernel_size=1, max_displacement=20
                 , stride1=1, stride2=2, corr_multiply=1):
        """Interface to CUDA implementation of the correlation layer.

        Args:
            pad_size: Padding for input feature maps.
            kernel_size: Spatial dimensions of kernels used for dot product.
            max_displacement: Maximum size of the window over which correlation is
                computed for each point in the input feature map.
            stride1: Stride used for first feature map.
            stride2: Stride for second feature map.

        """
        super(Correlation, self).__init__()
        self.pad_size = pad_size
        self.kernel_size = kernel_size
        self.max_displacement = max_displacement
        self.stride1 = stride1
        self.stride2 = stride2
        self.corr_multiply = corr_multiply

    def forward(self, input1, input2):
        output = torch.zeros(input1.shape, device=input1.device, dtype=input1.dtype)
        if input1.device.type == torch.device('cpu').type:
            output = torch.ops.my_ops.correlation_cpp_forward( input1, input2
                    , self.pad_size , self.kernel_size, self.max_displacement
                    , self.stride1 , self.stride2)
            return output
        elif input1.device.type == torch.device('cuda').type:
            rbot1 = torch.zeros(input1.shape, device=input1.device, dtype=input1.dtype)
            rbot2 = torch.zeros(input2.shape, device=input1.device, dtype=input1.dtype)
            output = torch.zeros(input1.shape, device=input1.device, dtype=input1.dtype)
            retval = torch.ops.my_ops.correlation_forward_cuda(input1, input2
                , rbot1, rbot2, output, self.pad_size, self.kernel_size
                , self.max_displacement, self.stride1, self.stride2
                , self.corr_multiply)
            return output
        return output


class Resample2d(nn.Module):
    """This class implements the Resample2D operation needed by LFNet.

    """

    def __init__(self):
        super(Resample2d, self).__init__()

    def forward(self, image_data, displacements):
        """Sample from image data using a displacements field. The displacements
        field locates each point x + displacements.x , y + displacements.y and
        the output is generated by linear interpolation.

        Args:
            image_data: Tensor containing image data.
            displacements: The displacement field over the image domain.
        """
        b, _, h, w = image_data.size()
        y, x = torch.meshgrid(torch.arange(h), torch.arange(w))
        y = y.repeat(b, 1, 1).to(displacements.device)
        x = x.repeat(b, 1, 1).to(displacements.device)
        y = (2 * (y + displacements[:, 1, :, :]) - h) / h
        x = (2 * (x + displacements[:, 0, :, :]) - w) / w
        xy = torch.stack((x, y), dim=3)
        sampled_data = F.grid_sample(image_data, xy, align_corners=True,
                           padding_mode='border')
        return sampled_data


class ChannelNorm(nn.Module):
    def __init__(self, norm_deg=2):
        super(ChannelNorm, self).__init__()
        self.norm_deg = norm_deg

    def forward(self, input):
        return torch.sqrt(
            torch.sum(torch.pow(input, self.norm_deg), dim=1)
        ).unsqueeze(0)
